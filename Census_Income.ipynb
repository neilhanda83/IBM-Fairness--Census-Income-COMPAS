{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206cdb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "import sys\n",
    "sys.path.insert(1, \"../\")  \n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "from aif360.datasets import AdultDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "\n",
    "from IPython.display import Markdown, display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ca7b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset and define protected attribute\n",
    "dataset_orig = AdultDataset(\n",
    "    protected_attribute_names=['sex'],           # Protected attribute: sex\n",
    "    privileged_classes=[['Male']],               # Males are considered privileged\n",
    "    features_to_drop=['race']                    # Dropping race attribute for simplicity\n",
    ")\n",
    "\n",
    "# Split dataset into training and test sets\n",
    "dataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=True)\n",
    "\n",
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18c3ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute fairness metrics for the original training dataset\n",
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaa22ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mitigate bias using the Reweighing technique\n",
    "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "                privileged_groups=privileged_groups)\n",
    "dataset_transf_train = RW.fit_transform(dataset_orig_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a92184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute fairness metrics for the transformed training dataset\n",
    "metric_transf_train = BinaryLabelDatasetMetric(dataset_transf_train, \n",
    "                                               unprivileged_groups=unprivileged_groups,\n",
    "                                               privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Transformed training dataset\"))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_transf_train.mean_difference())\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
